{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e33c5b0c-d0f1-40c0-b794-3b3471ac73d2",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 7: Clustering and recommender systems\n",
    "### Associated lectures: Lectures 14 and 15\n",
    "\n",
    "**Due date: Monday, March 21, 11:59pm**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4651888-484b-42a0-95e1-d273e5069205",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "\n",
    "#Added:\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086914c2-5de1-414a-8770-23bef9f312d0",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe22cb5-f825-4dba-b5e3-3538f4afe703",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330/blob/master/docs/homework_instructions.md). \n",
    "\n",
    "**You may work on this homework in a group and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be5b2d-1854-4c63-bcc6-9b6258b7293a",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d8d363-7c31-4381-8a1d-2b2556108916",
   "metadata": {},
   "source": [
    "## Exercise 1: Document clustering toy example <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "In lecture 14, we looked at a popular application of clustering: customer segmentation. In this homework, we will work on a toy example of another popular application: [**document clustering**](https://en.wikipedia.org/wiki/Document_clustering). A large amount of unlabeled text data is available out there (e.g., news, recipes, online Q&A), and clustering is a commonly used technique to organize this data in a meaningful way. \n",
    "\n",
    "In this exercise, we will create a toy dataset with sentences from Wikipedia articles and cluster these sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c7b268-4b0a-4d01-9009-a33312f65d33",
   "metadata": {},
   "source": [
    "### 1.1 Sample sentences from Wikipedia articles\n",
    "rubric={points:2}\n",
    "\n",
    "The code below extracts first sentences of Wikipedia articles on a set of queries. You will need the `wikipedia` package installed in the course environment to run the code below. \n",
    "\n",
    "```\n",
    "conda activate cpsc330\n",
    "conda install -c conda-forge wikipedia\n",
    "```\n",
    "\n",
    "You also need `nltk` library in the course environment. \n",
    "\n",
    "```\n",
    "conda install -c anaconda nltk \n",
    "```        \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following question. \n",
    "\n",
    "1. Given this dataset, how many clusters would you expect a clustering algorithm to identify? How would you manually label these clusters?   \n",
    "\n",
    "> *Note 2: Feel free to experiment with queries of your choice. But stick to the provided list for the final submission so that it's easier for the TAs when they grade your submission.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4d74b7-3750-48f6-ab60-411b3f6eb050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/abhi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c71b2eb-caf0-40f7-b7b0-93f1fadbc548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki query</th>\n",
       "      <th>text</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mango_fruit</td>\n",
       "      <td>A mango is an edible stone fruit produced by the tropical tree Mangifera indica which is believed to have originated from the region between northwestern Myanmar, Bangladesh, and northeastern India.</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pastry</td>\n",
       "      <td>Pastry is a dough of flour, water and shortening (solid fats, including butter or lard) that may be savoury or sweetened.</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Julia language</td>\n",
       "      <td>Julia is a high-level, high-performance, dynamic programming language.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python language</td>\n",
       "      <td>Python is a high-level, general-purpose programming language.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hockey</td>\n",
       "      <td>Hockey is a term used to denote various types of both summer and winter team sports which originated on either an outdoor field, sheet of ice, or dry floor such as in a gymnasium.</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>football</td>\n",
       "      <td>Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>supervised learning</td>\n",
       "      <td>Supervised learning (SL) is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unsupervised learning</td>\n",
       "      <td>Unsupervised learning  is a type of algorithm that learns patterns from untagged data.</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              wiki query  \\\n",
       "0  mango_fruit             \n",
       "1  pastry                  \n",
       "2  Julia language          \n",
       "3  Python language         \n",
       "4  hockey                  \n",
       "5  football                \n",
       "6  supervised learning     \n",
       "7  unsupervised learning   \n",
       "\n",
       "                                                                                                                                                                                                     text  \\\n",
       "0  A mango is an edible stone fruit produced by the tropical tree Mangifera indica which is believed to have originated from the region between northwestern Myanmar, Bangladesh, and northeastern India.   \n",
       "1  Pastry is a dough of flour, water and shortening (solid fats, including butter or lard) that may be savoury or sweetened.                                                                                \n",
       "2  Julia is a high-level, high-performance, dynamic programming language.                                                                                                                                   \n",
       "3  Python is a high-level, general-purpose programming language.                                                                                                                                            \n",
       "4  Hockey is a term used to denote various types of both summer and winter team sports which originated on either an outdoor field, sheet of ice, or dry floor such as in a gymnasium.                      \n",
       "5  Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.                                                                                                    \n",
       "6  Supervised learning (SL) is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.                                                        \n",
       "7  Unsupervised learning  is a type of algorithm that learns patterns from untagged data.                                                                                                                   \n",
       "\n",
       "   n_words  \n",
       "0  33       \n",
       "1  26       \n",
       "2  11       \n",
       "3  9        \n",
       "4  37       \n",
       "5  22       \n",
       "6  27       \n",
       "7  14       "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "queries = [\n",
    "    \"mango_fruit\",\n",
    "    \"pastry\",\n",
    "    \"Julia language\",\n",
    "    \"Python language\",\n",
    "    \"hockey\",\n",
    "    \"football\",\n",
    "    \"supervised learning\",\n",
    "    \"unsupervised learning\"    \n",
    "]\n",
    "\n",
    "wiki_dict = {\"wiki query\": [], \"text\": [], \"n_words\": []}\n",
    "for i in range(len(queries)):\n",
    "    sent = sent_tokenize(wikipedia.page(queries[i]).content)[0]\n",
    "    wiki_dict[\"text\"].append(sent)\n",
    "    wiki_dict[\"n_words\"].append(len(word_tokenize(sent)))\n",
    "    wiki_dict[\"wiki query\"].append(queries[i])\n",
    "\n",
    "wiki_df = pd.DataFrame(wiki_dict)\n",
    "wiki_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506b150-103f-4500-883c-1a85a903061e",
   "metadata": {},
   "source": [
    "I would expect these queries to be classified based on their similarities. Depending on the clustering algortihm and parameters given such as n_clusters, the amount clusters it evaluates to can vary. If I were to manually clustered, there are many possibilities, but one such example: cluster of Food (mango_fruit, pastry), Programming languages (Julia language, Python language), sports (hockey, football), and machine learning types (supervised learning, unsupervised learning). Thus, I would have 4 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f82cba-4642-4872-8b15-e49eab897821",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574346ba-94a4-4949-9be3-9ff8ea77488e",
   "metadata": {},
   "source": [
    "### 1.2 `KMeans` with bag-of-words representation \n",
    "rubric={points:4}\n",
    "\n",
    "We have seen that before we pass text to machine learning models, we need to encode it into a numeric representation. So let's encode our toy dataset above (`wiki_df`) to a numeric representation. \n",
    "\n",
    "First, let's try our good old friend: bag-of-words representation. The code below creates dense bag-of-words representation of Wikipedia sentences from 1.1 with [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following questions. \n",
    "\n",
    "1. Run `KMeans` clustering on the transformed data (`bow_sents`) with K = the number of clusters you identified in 1.1.  \n",
    "2. Examine clustering labels assigned by `KMeans`. Is `KMeans` doing a reasonable job in clustering the sentences? \n",
    "\n",
    "> You can access cluster label assignments using `labels_` attribute of the clustering object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09628f3b-0608-441a-af31-6f8f33ef46d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cpsc330/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>ball</th>\n",
       "      <th>bangladesh</th>\n",
       "      <th>based</th>\n",
       "      <th>believed</th>\n",
       "      <th>butter</th>\n",
       "      <th>data</th>\n",
       "      <th>degrees</th>\n",
       "      <th>denote</th>\n",
       "      <th>dough</th>\n",
       "      <th>...</th>\n",
       "      <th>tropical</th>\n",
       "      <th>type</th>\n",
       "      <th>types</th>\n",
       "      <th>unsupervised</th>\n",
       "      <th>untagged</th>\n",
       "      <th>used</th>\n",
       "      <th>various</th>\n",
       "      <th>varying</th>\n",
       "      <th>water</th>\n",
       "      <th>winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithm  ball  bangladesh  based  believed  butter  data  degrees  \\\n",
       "0  0          0     1           0      1         0       0     0         \n",
       "1  0          0     0           0      0         1       0     0         \n",
       "2  0          0     0           0      0         0       0     0         \n",
       "3  0          0     0           0      0         0       0     0         \n",
       "4  0          0     0           0      0         0       0     0         \n",
       "5  0          1     0           0      0         0       0     1         \n",
       "6  0          0     0           1      0         0       0     0         \n",
       "7  1          0     0           0      0         0       1     0         \n",
       "\n",
       "   denote  dough  ...  tropical  type  types  unsupervised  untagged  used  \\\n",
       "0  0       0      ...  1         0     0      0             0         0      \n",
       "1  0       1      ...  0         0     0      0             0         0      \n",
       "2  0       0      ...  0         0     0      0             0         0      \n",
       "3  0       0      ...  0         0     0      0             0         0      \n",
       "4  1       0      ...  0         0     1      0             0         1      \n",
       "5  0       0      ...  0         0     0      0             0         0      \n",
       "6  0       0      ...  0         0     0      0             0         0      \n",
       "7  0       0      ...  0         1     0      1             1         0      \n",
       "\n",
       "   various  varying  water  winter  \n",
       "0  0        0        0      0       \n",
       "1  0        0        1      0       \n",
       "2  0        0        0      0       \n",
       "3  0        0        0      0       \n",
       "4  1        0        0      1       \n",
       "5  0        1        0      0       \n",
       "6  0        0        0      0       \n",
       "7  0        0        0      0       \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english')\n",
    "bow_sents = vec.fit_transform(wiki_df[\"text\"]).todense()\n",
    "bow_df = pd.DataFrame(\n",
    "    data=bow_sents, columns=vec.get_feature_names(), index=wiki_df.index\n",
    ")\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94e1955e-f49e-4c87-aef4-d782e60a3d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 1 0 1\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1\n",
      "  1 0 0 0 1 0 0 1 1 0 0 1]\n",
      " [0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0\n",
      "  0 3 0 0 1 0 0 1 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 1 1 0 0 0 0 0]]\n",
      "[2 1 1 1 3 1 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cpsc330/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/cpsc330/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(bow_sents)\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(bow_sents)\n",
    "\n",
    "predictedClustersKBow = kmeans.predict(bow_sents)\n",
    "print(predictedClustersKBow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e9174d-c281-4bcd-bd8f-8f1cb81e4bd9",
   "metadata": {},
   "source": [
    "Predictions by K-means:\n",
    "    Cluster 0: supervised learning\n",
    "    Cluster 1: pastry, Julia language, Python language, football, unsupervised learning\n",
    "    Cluster 2: mango_fruit\n",
    "    Cluster 3: hockey\n",
    "\n",
    "K-means is doing a very poor job at clustering these queries, for example pastry and unsupervised learning are clustered together even though they don't share any obvious similarities.\n",
    "The algorithm missed obvious similarities such as (supervised learning and unsupervised learning) OR (Julia language, Python language) and others as predicted in Exercise 1.1 above.\n",
    "This is likely because K-Means highly relies on the placement of the random clustered centres and due to this randomness, the results didn't align well in this case. Not to mention the bag of words data it is working with only provides the count of every word in that query, therefore missing any contextual information to make a good clustering assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02261e6d-8195-4248-9c21-5bc520baa89e",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e1b0b-faec-4b86-9e59-b45b3a133e2f",
   "metadata": {},
   "source": [
    "### 1.3 Sentence embedding representation\n",
    "rubric={points:6}\n",
    "\n",
    "Clustering is sensitive to what kind of representation we use for the given data. \n",
    "Bag-of-words representation is limited in that it does not take into account word ordering and context. There are other richer representations of text, and we are going to use one such representation in this exercise. \n",
    "\n",
    "The code below creates an alternative and a more expressive representation of sentences. We will call it *sentence embedding representation*. We'll use [sentence transformer](https://www.sbert.net/index.html) to extract these representations. At this point it's enough to know that this is an alternative representation of text which usually works better than simple bag-of-words representation. We will talk a bit more about embedding representations next week. You need to install `sentence-transformers` in the course conda environment to run the code below. \n",
    "\n",
    "```\n",
    "conda activate cpsc330\n",
    "conda install -c conda-forge sentence-transformers\n",
    "```\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following questions. \n",
    "\n",
    "1. How many dimensions (features associated with each example) are present in this representation? \n",
    "2. Run `KMeans` clustering with sentence embedding representation of text (`emb_sents`) and examine cluster labels. \n",
    "3. How well the sentences are clustered together? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a092544-58d7-418d-84ff-2e898ece2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer(\"paraphrase-distilroberta-base-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20174ee5-9122-4c10-b112-4a675653fee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.056666</td>\n",
       "      <td>-0.025778</td>\n",
       "      <td>0.248908</td>\n",
       "      <td>-0.052198</td>\n",
       "      <td>-0.046876</td>\n",
       "      <td>0.202116</td>\n",
       "      <td>0.235076</td>\n",
       "      <td>0.322160</td>\n",
       "      <td>-0.023798</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239582</td>\n",
       "      <td>-0.022871</td>\n",
       "      <td>0.071445</td>\n",
       "      <td>0.402666</td>\n",
       "      <td>-0.134781</td>\n",
       "      <td>0.177697</td>\n",
       "      <td>-0.123652</td>\n",
       "      <td>0.446758</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>-0.048541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.062657</td>\n",
       "      <td>0.214339</td>\n",
       "      <td>-0.025160</td>\n",
       "      <td>0.276730</td>\n",
       "      <td>0.401149</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>-0.089944</td>\n",
       "      <td>0.331922</td>\n",
       "      <td>-0.247056</td>\n",
       "      <td>0.175028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039294</td>\n",
       "      <td>-0.100197</td>\n",
       "      <td>0.201216</td>\n",
       "      <td>0.257111</td>\n",
       "      <td>0.194594</td>\n",
       "      <td>0.280075</td>\n",
       "      <td>0.037366</td>\n",
       "      <td>0.205146</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>-0.078719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063674</td>\n",
       "      <td>0.287056</td>\n",
       "      <td>0.098705</td>\n",
       "      <td>0.048766</td>\n",
       "      <td>0.562877</td>\n",
       "      <td>-0.015978</td>\n",
       "      <td>-0.129418</td>\n",
       "      <td>0.098363</td>\n",
       "      <td>0.249305</td>\n",
       "      <td>0.269618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483838</td>\n",
       "      <td>-0.017338</td>\n",
       "      <td>0.194521</td>\n",
       "      <td>0.185484</td>\n",
       "      <td>0.536235</td>\n",
       "      <td>0.137246</td>\n",
       "      <td>0.368982</td>\n",
       "      <td>-0.028611</td>\n",
       "      <td>-0.017652</td>\n",
       "      <td>-0.192852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101454</td>\n",
       "      <td>0.046038</td>\n",
       "      <td>0.127588</td>\n",
       "      <td>-0.036343</td>\n",
       "      <td>0.478972</td>\n",
       "      <td>0.132067</td>\n",
       "      <td>-0.035593</td>\n",
       "      <td>0.390519</td>\n",
       "      <td>0.188474</td>\n",
       "      <td>0.348842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321179</td>\n",
       "      <td>0.367853</td>\n",
       "      <td>0.154809</td>\n",
       "      <td>0.116112</td>\n",
       "      <td>0.101856</td>\n",
       "      <td>0.278487</td>\n",
       "      <td>0.233325</td>\n",
       "      <td>0.111571</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>-0.154422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.076768</td>\n",
       "      <td>0.098353</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>-0.506420</td>\n",
       "      <td>0.608778</td>\n",
       "      <td>0.077222</td>\n",
       "      <td>0.387065</td>\n",
       "      <td>0.198607</td>\n",
       "      <td>-0.127567</td>\n",
       "      <td>0.250499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513450</td>\n",
       "      <td>-0.410064</td>\n",
       "      <td>-0.048727</td>\n",
       "      <td>-0.169649</td>\n",
       "      <td>-0.246023</td>\n",
       "      <td>-0.013514</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.257681</td>\n",
       "      <td>0.477911</td>\n",
       "      <td>-0.241455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.071756</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>-0.071762</td>\n",
       "      <td>0.306060</td>\n",
       "      <td>0.358961</td>\n",
       "      <td>-0.061443</td>\n",
       "      <td>0.167584</td>\n",
       "      <td>0.364614</td>\n",
       "      <td>0.323541</td>\n",
       "      <td>0.141398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404115</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.177493</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.232335</td>\n",
       "      <td>0.260556</td>\n",
       "      <td>0.168149</td>\n",
       "      <td>0.483963</td>\n",
       "      <td>0.121122</td>\n",
       "      <td>0.196881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.056006</td>\n",
       "      <td>-0.111174</td>\n",
       "      <td>-0.041484</td>\n",
       "      <td>0.279774</td>\n",
       "      <td>0.758024</td>\n",
       "      <td>0.181266</td>\n",
       "      <td>0.128420</td>\n",
       "      <td>0.323363</td>\n",
       "      <td>0.297055</td>\n",
       "      <td>0.154679</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007967</td>\n",
       "      <td>-0.061346</td>\n",
       "      <td>0.352495</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>-0.358587</td>\n",
       "      <td>-0.052314</td>\n",
       "      <td>0.370847</td>\n",
       "      <td>-0.276011</td>\n",
       "      <td>0.105793</td>\n",
       "      <td>0.175194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.240444</td>\n",
       "      <td>-0.395717</td>\n",
       "      <td>-0.009280</td>\n",
       "      <td>0.217371</td>\n",
       "      <td>0.510593</td>\n",
       "      <td>0.215532</td>\n",
       "      <td>0.100368</td>\n",
       "      <td>-0.008069</td>\n",
       "      <td>0.137967</td>\n",
       "      <td>-0.027900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223550</td>\n",
       "      <td>-0.093406</td>\n",
       "      <td>-0.088631</td>\n",
       "      <td>0.252510</td>\n",
       "      <td>-0.288174</td>\n",
       "      <td>0.081506</td>\n",
       "      <td>0.261480</td>\n",
       "      <td>-0.533761</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.126381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.056666 -0.025778  0.248908 -0.052198 -0.046876  0.202116  0.235076   \n",
       "1 -0.062657  0.214339 -0.025160  0.276730  0.401149  0.030865 -0.089944   \n",
       "2  0.063674  0.287056  0.098705  0.048766  0.562877 -0.015978 -0.129418   \n",
       "3  0.101454  0.046038  0.127588 -0.036343  0.478972  0.132067 -0.035593   \n",
       "4 -0.076768  0.098353  0.002281 -0.506420  0.608778  0.077222  0.387065   \n",
       "5 -0.071756  0.133156 -0.071762  0.306060  0.358961 -0.061443  0.167584   \n",
       "6  0.056006 -0.111174 -0.041484  0.279774  0.758024  0.181266  0.128420   \n",
       "7  0.240444 -0.395717 -0.009280  0.217371  0.510593  0.215532  0.100368   \n",
       "\n",
       "          7         8         9  ...       758       759       760       761  \\\n",
       "0  0.322160 -0.023798  0.133034  ...  0.239582 -0.022871  0.071445  0.402666   \n",
       "1  0.331922 -0.247056  0.175028  ...  0.039294 -0.100197  0.201216  0.257111   \n",
       "2  0.098363  0.249305  0.269618  ...  0.483838 -0.017338  0.194521  0.185484   \n",
       "3  0.390519  0.188474  0.348842  ...  0.321179  0.367853  0.154809  0.116112   \n",
       "4  0.198607 -0.127567  0.250499  ...  0.513450 -0.410064 -0.048727 -0.169649   \n",
       "5  0.364614  0.323541  0.141398  ...  0.404115  0.000236  0.177493  0.016162   \n",
       "6  0.323363  0.297055  0.154679  ... -0.007967 -0.061346  0.352495  0.011700   \n",
       "7 -0.008069  0.137967 -0.027900  ...  0.223550 -0.093406 -0.088631  0.252510   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0 -0.134781  0.177697 -0.123652  0.446758  0.204768 -0.048541  \n",
       "1  0.194594  0.280075  0.037366  0.205146  0.044872 -0.078719  \n",
       "2  0.536235  0.137246  0.368982 -0.028611 -0.017652 -0.192852  \n",
       "3  0.101856  0.278487  0.233325  0.111571  0.009258 -0.154422  \n",
       "4 -0.246023 -0.013514  0.007321  0.257681  0.477911 -0.241455  \n",
       "5  0.232335  0.260556  0.168149  0.483963  0.121122  0.196881  \n",
       "6 -0.358587 -0.052314  0.370847 -0.276011  0.105793  0.175194  \n",
       "7 -0.288174  0.081506  0.261480 -0.533761  0.008995  0.126381  \n",
       "\n",
       "[8 rows x 768 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sents = embedder.encode(wiki_df[\"text\"])\n",
    "emb_sent_df = pd.DataFrame(emb_sents, index=wiki_df.index)\n",
    "emb_sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a99e0da-c763-4f02-a7b1-cc277200ff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05666572 -0.02577795  0.24890848 ...  0.44675797  0.20476833\n",
      "  -0.04854143]\n",
      " [-0.06265676  0.21433944 -0.02516016 ...  0.20514563  0.04487206\n",
      "  -0.07871928]\n",
      " [ 0.06367427  0.28705606  0.0987052  ... -0.02861143 -0.01765239\n",
      "  -0.19285212]\n",
      " ...\n",
      " [-0.07175568  0.13315631 -0.07176156 ...  0.48396263  0.12112183\n",
      "   0.19688086]\n",
      " [ 0.05600616 -0.11117412 -0.04148366 ... -0.27601126  0.10579337\n",
      "   0.17519434]\n",
      " [ 0.24044433 -0.39571723 -0.00927978 ... -0.53376144  0.00899484\n",
      "   0.12638092]]\n",
      "[3 3 2 2 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(emb_sents)\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(emb_sents)\n",
    "\n",
    "predictedClustersKEmb = kmeans.predict(emb_sents)\n",
    "print(predictedClustersKEmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e1c1c-657e-4ea5-9145-a65a495dc05d",
   "metadata": {},
   "source": [
    "1) There are 768 dimensions/features associated with each example.\n",
    "\n",
    "3)\n",
    "Cluster 0: hockey, football\n",
    "Cluster 1: supervised learning, unsupervised learning\n",
    "Cluster 2: Julia language, Python language\n",
    "Cluster 3: mango_fruit, pastry\n",
    "\n",
    "The predictions made by K-Means this time matches exactly as to what I predicted in Exercise 1.1. Clusters of programming language, sports, machine learning types, and food => 4 clusters. Using sentence-transformers did a far better/useful job at parsing the queries than bag of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a67c7a-83a4-473a-b710-f31c01f4b6fc",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f7a64-57c5-4511-a2c7-bd319dfdc8b7",
   "metadata": {},
   "source": [
    "### 1.4 DBSCAN with cosine distance  \n",
    "rubric={points:8}\n",
    "\n",
    "Let's try `DBSCAN` on our toy dataset. K-Means is kind of bound to the Euclidean distance because it is based on the notion of means. With `DBSCAN` we can try different distance metrics. In the context of text (sparse data), [cosine similarities](https://scikit-learn.org/stable/modules/metrics.html#cosine-similarity) or cosine distances tend to work better. Given vectors $u$ and $v$, the **cosine distance** between the vectors is defined as: \n",
    "\n",
    "$$distance_{cosine}(u,v) = 1 - (\\frac{u \\cdot v}{\\left\\lVert u\\right\\rVert_2 \\left\\lVert v\\right\\rVert_2})$$\n",
    "\n",
    "In this exercise, you'll use DBSCAN with cosine distances. \n",
    "\n",
    "**Your tasks**\n",
    "\n",
    "1. Use DBSCAN to cluster our toy data using sentence embedding representation (`emb_sents`) and `metric='cosine'`. \n",
    "2. Briefly comment on the number of clusters identified and the cluster assignment given by the algorithm.\n",
    "\n",
    "> *Note: You will also have to set appropriate values for the hyperparamters `eps` and `min_samples` to get meaningful clusters, as default values for these hyperparameters won't work on this toy dataset. In order to set appropriate value for `eps`, you may want to examine the distances given by [sklearn's `cosine_distance`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_distances.html).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccc76682-95d3-4067-a395-0c3308d1a5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  0  0  1  1  2  2]\n"
     ]
    }
   ],
   "source": [
    "distances = cosine_distances(emb_sents, emb_sents)\n",
    "avgDist = np.mean(distances)\n",
    "\n",
    "#I am picking min_samples to be 2, since in my manual prediction, I expected every cluster to have at least 2 items. \n",
    "#It is also reasonable for a cluster to at least contain 2 items, since 1 would be every item being its own cluster.\n",
    "dbscan = DBSCAN(eps = avgDist, min_samples=2, metric='cosine')\n",
    "dbscan.fit(emb_sents)\n",
    "predictedClustersDbEmb = dbscan.labels_\n",
    "print(predictedClustersDbEmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bf9ec1-010c-4a59-bd5a-2d9e9e6aced5",
   "metadata": {},
   "source": [
    "DBSCAN identified 3 clusters.\n",
    "Cluster 0: Julia language, python language\n",
    "Cluster 1: hockey, football\n",
    "Cluster 2: supervised learning, unsupervised learning\n",
    "\n",
    "It labelled mango_fruit and pastry as noise points, likely because of the value used for eps hyperparameter was not large enough to consider these two points as being close enough to be a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f359f90-e90c-4311-adb2-39b6f9a3433c",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30b339-3799-4d4c-b9d5-c0c048243c1f",
   "metadata": {},
   "source": [
    "### 1.5 Visualizing clusters \n",
    "rubric={points:5}\n",
    "\n",
    "One thing we could do with unlabeled data is visualizing it. That said, our data is high dimensional (each example is represented with 768 dimensions) and high-dimensional data is hard to visualize. One way to visualize high-dimensional data is applying dimensionality reduction to get the most important (2 or 3) components of the dataset and visualizing this low-dimensional data. \n",
    "\n",
    "Given data as a `numpy` array and cluster assignments, the `plot_pca_clusters` function below transforms the given data by applying dimensionality reduction and plots the transformed data into corresponding clusters. \n",
    "\n",
    "> *Note: At this point we are using this function only for visualization and you are not expected to understand the PCA part. Feel free to modify the function as you see fit.*\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Call the function `plot_pca_clusters` to visualize the clusters created by the three models above:\n",
    "    - KMeans with bag-of-words representation \n",
    "    - KMeans with sentence embedding representation \n",
    "    - DBSCAN with sentence embedding representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5531c582-11c4-4691-8110-4ccc7342fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # Obtain the principal components\n",
    "\n",
    "def plot_pca_clusters(\n",
    "    data,\n",
    "    cluster_labels,\n",
    "    raw_sents=wiki_df[\"text\"],\n",
    "    show_labels=False,\n",
    "    size=100,\n",
    "    title=\"PCA visualization\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Carry out dimensionality reduction using PCA and plot 2-dimensional clusters.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    data : numpy array\n",
    "        data as a numpy array\n",
    "    cluster_labels : list\n",
    "        cluster labels for each row in the dataset\n",
    "    raw_sents : list\n",
    "        the original raw sentences for labeling datapoints\n",
    "    show_labels : boolean\n",
    "        whether you want to show labels for points or not (default: False)\n",
    "    size : int\n",
    "        size of points in the scatterplot\n",
    "    title : str\n",
    "        title for the visualization plot\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    None. Shows the clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_comp = pca.fit_transform(data)\n",
    "    pca_df = pd.DataFrame(data=principal_comp, columns=[\"pca1\", \"pca2\"])\n",
    "    pca_df[\"cluster\"] = cluster_labels\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.title(title)\n",
    "    ax = sns.scatterplot(\n",
    "        x=\"pca1\", y=\"pca2\", hue=\"cluster\", data=pca_df, palette=\"tab10\", s=size\n",
    "    )\n",
    "\n",
    "    x = pca_df[\"pca1\"].tolist()\n",
    "    y = pca_df[\"pca2\"].tolist()\n",
    "    if show_labels:\n",
    "        for i, txt in enumerate(raw_sents):\n",
    "            plt.annotate(\" \".join(txt.split()[:10]), (x[i], y[i]))\n",
    "        ax.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8898a3c9-bb20-4e75-b9b8-03ff99f569f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cpsc330/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pca_clusters(data=bow_sents, cluster_labels=predictedClustersKBow)\n",
    "plot_pca_clusters(data=emb_sents, cluster_labels=predictedClustersKEmb)\n",
    "plot_pca_clusters(data=emb_sents, cluster_labels=predictedClustersDbEmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60195d0-3070-43e5-8d76-b59bf9796a6b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0bf74a4-86f7-479f-ac54-4fbd0709b126",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d135d-cf62-4a8c-990d-631ee1662913",
   "metadata": {},
   "source": [
    "## Exercise 2: Movie recommendations\n",
    "<hr>\n",
    "\n",
    "Let's build simple movie recommendation systems using the [MovieLens dataset](https://www.kaggle.com/prajitdatta/movielens-100k-dataset/data). The original source of the data is [here](https://grouplens.org/datasets/movielens/), and the structure of the data is described in the [README](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html) that comes with it. The code below reads the data as a CSV assuming that it's under `data/ml-100k/` directory under your lab folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41780f0a-8c8d-4baf-8059-cf428dad85cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0  196      242       3       881250949\n",
       "1  186      302       3       891717742\n",
       "2  22       377       1       878887116\n",
       "3  244      51        2       880606923\n",
       "4  166      346       1       886397596"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cols = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "ratings = pd.read_csv(\n",
    "    os.path.join(\"data\", \"ml-100k\", \"u.data\"),\n",
    "    sep=\"\\t\",\n",
    "    names=r_cols,\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "206ca960-e598-48ba-b506-3710e3714047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using these keys later in the starter code\n",
    "user_key = \"user_id\"\n",
    "item_key = \"movie_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05efce7-bc1e-4ff1-888c-5053b4f57479",
   "metadata": {},
   "source": [
    "### 2.1 Terminology\n",
    "rubric={points:3}\n",
    "\n",
    "Here is some notation we will be using in this homework. \n",
    "\n",
    "**Constants**:\n",
    "\n",
    " - $N$: the number of users, indexed by $n$\n",
    " - $M$: the number of movies, indexed by $m$\n",
    " - $\\mathcal{R}$: the set of indices $(n,m)$ where we have ratings in the utility matrix $Y$\n",
    "    - Thus $|\\mathcal{R}|$ is the total number of ratings\n",
    " \n",
    "**The data**:\n",
    "\n",
    " - $Y$: the utility matrix containing ratings, with a lot of missing entries\n",
    " - `train_mat` and `valid_mat`: Utility matrices for train and validation sets, respectively\n",
    " \n",
    "    \n",
    "**Your tasks:**    \n",
    "\n",
    "1. What are the values of $N$ and $M$ in movie ratings data?  \n",
    "2. What would be the shape of the dense utility matrix $Y$? \n",
    "3. What would be the fraction of non missing ratings in the utility matrix $Y$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29d8fc62-3d8f-4879-a19c-8972e4adf89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 100000\n",
      "Average rating:  3.530\n",
      "Number of users (N): 943\n",
      "Number of items (M): 1682\n",
      "Fraction non-nan ratings: 0.063\n"
     ]
    }
   ],
   "source": [
    "# Taken from lecture 15\n",
    "def get_stats(ratings, item_key=item_key, user_key=user_key):\n",
    "    print(\"Number of ratings:\", len(ratings))\n",
    "    print(\"Average rating:  %0.3f\" % (np.mean(ratings[\"rating\"])))\n",
    "    N = len(np.unique(ratings[user_key]))\n",
    "    M = len(np.unique(ratings[item_key]))\n",
    "    print(\"Number of users (N): %d\" % N)\n",
    "    print(\"Number of items (M): %d\" % M)\n",
    "    print(\"Fraction non-nan ratings: %0.3f\" % (len(ratings) / (N * M)))\n",
    "    return N, M\n",
    "\n",
    "\n",
    "N, M = get_stats(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40744eb3-0f31-4237-934e-4694fa82192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 943\n",
    "M = 1682"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810fb2f-d56c-4869-8741-15da6fb265dc",
   "metadata": {},
   "source": [
    "1) N = the number of users = 943. M = the number of movies = 1682.\n",
    "2) Dimensions of utility matrix Y will be: 943 x 1682\n",
    "3) \n",
    "    Since the dimensions are 943 x 1682. The total amount of cells are 943 x 1682 = 1 586 126, but we only have 100 000 ratings.\n",
    "    Therefore, fraction of non-missing ratings is equal to 100 000 / 1 586 126 = 0.06304 or 6.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c433a44-37b9-4113-8102-10d918cc84ac",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af68b939-60c8-4da8-a32e-384b887656b8",
   "metadata": {},
   "source": [
    "### 2.2 Splitting the data\n",
    "rubric={points:5}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the ratings data with `test_size=0.2` and `random_state=42`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e210d7b-a363-4ab8-b9fd-a3794f14b5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000, 4), (20000, 4))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taken from lecture 15\n",
    "X = ratings.copy()\n",
    "y = ratings[user_key]\n",
    "            \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8152e2be-565c-4244-9e7c-84837bf1b35b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce1526cf-a7e5-425e-b8e5-dd8cadb53a50",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb483ab-ae9a-4d3d-a2d5-be404c422c14",
   "metadata": {},
   "source": [
    "### 2.3 Utility matrix \n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Create utility matrices for train and validation sets (similar to how we did in the class). \n",
    "2. Briefly explain the difference between the train and validation utility matrices. \n",
    "\n",
    "> You may use the code from lecture notes with appropriate attributions.  \n",
    "\n",
    "> You won't do it in real life but since our dataset is not that big, create a dense utility matrix in this assignment. You are welcome to try sparse matrix but then you may have to change some started code provided in the later exercises.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b8d514-615a-4166-b597-eee2e53dbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(N))))\n",
    "# print(user_mapper)\n",
    "item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(M))))\n",
    "# print(item_mapper)\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(ratings[user_key])))\n",
    "# print(user_inverse_mapper)\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(ratings[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "437fa48f-a2b9-4263-a59c-da3941df6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Lecture 15\n",
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"rating\"]\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "192d8a08-c194-45c2-83ca-63156311401e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((943, 1682), (943, 1682))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat = create_Y_from_ratings(X_train, N, M)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M)\n",
    "train_mat.shape, valid_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d54bf-dfbd-495d-97ac-d550658d4b80",
   "metadata": {},
   "source": [
    "Even though the shape of both utility matrices are the same at N x M = 943 x 1682, the validation utility matrix is far more sparse with more NaNs, since X_valid only has 20000 examples while X_train has 80000. \n",
    "This is because the data has been split in a way such that we can impute missing ratings on the training matrix, and then compare it to the imputation of missing ratings on the validation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce90c62-f51b-4c35-a136-52176cbf8ea3",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b8ac2-56be-4193-abda-fea9d4cefb4a",
   "metadata": {},
   "source": [
    "### 2.4 Evaluation and baseline\n",
    "rubric={points:4}\n",
    "\n",
    "To compare different models you build in this homework, let's write a couple of functions for evaluation. \n",
    "- The `error` function returns RMSE.\n",
    "- The `evaluate` function prints the train and validation RMSEs. \n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Briefly explain what exactly we are comparing to evaluate recommender systems. \n",
    "2. Implement the global average baseline, where you predict everything as the global average rating. What's the RMSE of the global average baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15c3c76a-5d5b-4773-a48c-0f26d5ec5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat, valid_mat, model_name=\"Global average\"):\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c649565-f631-42e6-97b3-944d7383b392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "1  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "2  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "3  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "4  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "\n",
       "          7         8         9  ...      1672      1673      1674      1675  \\\n",
       "0  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "1  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "2  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "3  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "4  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "\n",
       "       1676      1677      1678      1679      1680      1681  \n",
       "0  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "1  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "2  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "3  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "4  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taken from Lecture 15\n",
    "\n",
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "pd.DataFrame(pred_g).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39901426-b9f2-4ee7-8228-3007e1cdcd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average rating train RMSE: 1.13\n",
      "Global average rating valid RMSE: 1.12\n"
     ]
    }
   ],
   "source": [
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757ffcd-be92-4cfb-a5a2-14299a6b7a8c",
   "metadata": {},
   "source": [
    "1) We are using the average value  of the training set to determine what rating value should be used for imputation. This RMSE error calculates the difference between the rating value we determined for imputation using the training set compared to the actual rating for examples in the training/validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a6ab6-62ef-4fdd-ba0d-5e7e920154a3",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a02d5-bf63-428a-8bac-9fa6f2f38681",
   "metadata": {},
   "source": [
    "### (Optional) 2.5 $k$-nearest neighbours imputation\n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Try [KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html) to fill in the missing entries. Discuss your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7729948c-3e07-4a69-97e4-c94e2432db65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=10)\n",
    "train_mat_imp = imputer.fit_transform(train_mat)\n",
    "train_mat_imp_df = pd.DataFrame(train_mat_imp)\n",
    "\n",
    "\n",
    "\n",
    "# Transform validation matrix since training matrix has columns that can't be imputed\n",
    "train_mat_df = pd.DataFrame(train_mat)\n",
    "# These are the columns that are being deleted since they only contain null values and thus cannot be imputed.\n",
    "columnIdxDel = train_mat_df.columns[train_mat_df.isnull().all()]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Dropping these columns since they are being dropped in the training matrix due to being empty                                    \n",
    "valid_mat_mod = valid_mat.copy()\n",
    "valid_mat_mod_df = pd.DataFrame(valid_mat_mod)  \n",
    "\n",
    "valid_mat_mod_df = valid_mat_mod_df.drop(columns=columnIdxDel)\n",
    "# valid_mat_mod_df\n",
    "\n",
    "train_mat_mod = train_mat.copy()\n",
    "train_mat_mod_df = pd.DataFrame(train_mat_mod)  \n",
    "\n",
    "train_mat_mod_df = train_mat_mod_df.drop(columns=columnIdxDel)\n",
    "# train_mat_mod_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb45ea91-415a-4b80-86aa-89ccfd4c446d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3    4    5    6    7    8    9  ...  1643  1644  1645  \\\n",
      "0    4.0  3.0  4.0  3.7  3.0  3.8  4.0  3.3  5.0  3.0  ...  3.0   3.0   1.0    \n",
      "1    4.0  3.0  3.3  4.1  3.2  4.3  4.4  4.4  4.5  4.1  ...  3.0   3.0   1.0    \n",
      "2    3.8  3.2  2.8  3.1  3.5  3.5  4.0  3.7  3.7  4.3  ...  3.0   3.0   1.0    \n",
      "3    4.1  2.9  3.9  3.1  3.6  3.8  3.3  4.3  4.2  4.2  ...  3.0   3.0   1.0    \n",
      "4    4.0  3.0  3.3  3.8  3.3  4.1  4.0  3.8  3.8  4.1  ...  3.0   3.0   1.0    \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...    \n",
      "938  3.8  3.7  3.7  3.5  4.0  4.1  4.0  3.9  5.0  4.3  ...  3.0   3.0   1.0    \n",
      "939  4.1  3.2  3.6  2.0  3.3  3.6  3.7  4.1  3.0  4.3  ...  3.0   3.0   1.0    \n",
      "940  5.0  3.4  2.9  3.8  3.3  3.6  4.3  3.8  4.5  3.6  ...  3.0   3.0   1.0    \n",
      "941  4.2  3.4  3.6  3.4  4.0  4.0  3.5  4.3  4.0  4.0  ...  3.0   3.0   1.0    \n",
      "942  4.3  5.0  3.2  3.6  3.3  4.0  3.7  4.4  3.0  4.1  ...  3.0   3.0   1.0    \n",
      "\n",
      "     1646  1647  1648  1649  1650  1651  1652  \n",
      "0    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
      "1    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
      "2    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
      "3    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
      "4    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
      "..   ...   ...   ...   ...   ...   ...   ...   \n",
      "938  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
      "939  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
      "940  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
      "941  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
      "942  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
      "\n",
      "[943 rows x 1653 columns]\n",
      "KNN imputer train RMSE: 0.50\n",
      "KNN imputer valid RMSE: 1.02\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(train_mat_imp_df))\n",
    "evaluate(train_mat_imp_df, train_mat_mod_df, valid_mat_mod_df, model_name=\"KNN imputer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8567e44d-bf19-4664-b4bf-9dfd4234add2",
   "metadata": {},
   "source": [
    "The validation RMSE is slightly better than the base line at 1.02 (an improvement of 1.12-1.02 = 0.10). Looking at the imputed training set, K-NN imputers is uses a more complicated strategy than the baseline, as it doesn't replace every value with the average. It keeps the ratings in the training set for which there were ratings already present and ONLY imputed missing ratings. This is why the training RMSE is significantly better than baseline at 0.50 compared to 1.13."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65bf17-79e9-4b85-9739-bfc9faf540fa",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d2e8f-e22a-4377-9110-fff8d041289e",
   "metadata": {},
   "source": [
    "### 2.6 Use collaborative filtering with the `surprise` package\n",
    "rubric={points:6}\n",
    "\n",
    "Use the [`surprise`](https://surprise.readthedocs.io/en/stable/) package which has implementation of SVD algorithm for collaborative filtering. You can install it as follows in your conda environment. \n",
    "\n",
    "```\n",
    ">> conda activate cpsc330\n",
    ">> conda install -c conda-forge scikit-surprise\n",
    "or \n",
    ">> pip install scikit-surprise\n",
    "```\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out cross-validation using SVD algorithm in the package, similar to how we did it in the lecture on Jester dataset. Report mean RMSE and compare it with global baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b84213d-6fd4-4aee-9dae-5fc864b72301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from Lecture 15\n",
    "#Drop unncessary columns in ratings\n",
    "ratings_copy = ratings.copy()\n",
    "ratings_copy = ratings_copy.drop(columns=\"timestamp\")\n",
    "\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings_copy, reader)  # Load the data\n",
    "\n",
    "trainset, validset = surprise.model_selection.train_test_split(\n",
    "    data, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "143a7233-f2be-42e0-b8b5-e26ad89d5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.932839700199596"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taken from Lecture 15\n",
    "algo = SVD(n_factors=10, random_state=42)\n",
    "algo.fit(trainset)\n",
    "svd_preds = algo.test(validset)\n",
    "accuracy.rmse(svd_preds, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63c1f7-82d3-4532-82d7-2d55c8f596d5",
   "metadata": {},
   "source": [
    "The root mean square from SVD is 0.93, where as the RMSE using baseline for validation set is 1.12. 0.93-1.12/1.12 = 0.169 or 16.9% improvement.\n",
    "Thus, the improvement is not very large over the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a044157f-1236-4cb9-8c76-82647f23cc99",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d184a9-7fad-4e34-8fa7-b10443d83911",
   "metadata": {},
   "source": [
    "## Exercise 3: Short answer questions\n",
    "<hr>\n",
    "\n",
    "rubric={points:5}\n",
    "\n",
    "Answer the following short-answer questions: \n",
    "\n",
    "1. What's the main difference between unsupervised and supervised learning?\n",
    "2. When choosing $k$ in K-Means, why not just choose the $k$ that leads to the smallest inertia (sum of squared distances within clusters)?\n",
    "3. You decide to use clustering for _outlier detection_; that is, to detect instances that are very atypical compared to all the rest. How might you do this with $k$-means?\n",
    "4. You decide to use clustering for _outlier detection_; that is, to detect instances that are very atypical compared to all the rest. How might you do this with DBSCAN?\n",
    "5. How might you apply clustering to recommendation systems? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43410bc8-d121-4da6-997b-b84cbf419e16",
   "metadata": {},
   "source": [
    "1) \n",
    "    The main difference is that unsupervised learning often tries to find patterns from a unlabelled dataset where as supervised learning has a labelled dataset (containing targets).\n",
    "\n",
    "2) \n",
    "    We don't choose k in order to get the smallest inertia because the smallest intertia is associated with larger and larger values of k. Eventually if the value of k is bigger than the amount of examples in the dataset, every example will be classified as its own cluster by itself, making our model useless in determining patterns through clustering.\n",
    "\n",
    "3) \n",
    "    K-Means is unable to detect outliers and is actually one of its weaknesses since outliers can greatly skew k-mean results, as clustered centers move towards them. This is also because K-Means labels every point in the dataset, it doesn't consider any point as noise/outliers.\n",
    "\n",
    "4) \n",
    "    DBSCAN has two hyperparameters we can tune: eps and min_samples. eps represents the distance between points that we can consider to be close enough to be part of a cluster, where as min_samples represents the minimum amount of points within eps distance that can be considered a cluster. Therefore, to detect outliers, a good strategy would be to use a reasonable value for eps by analyzing the average distance between datapoints like we did in exercise 1.4 using cosine_distances matrix, we do this to avoid using very large values that would consider outliers/noise points as being \"close enough\". Generally smaller eps values will be better than larger values at finding noise points. As for min_samples, a good strategy is to prefer a larger value over a smaller value, because noise/outliers by definition are not the norm and therefore usually isolated from other normally placed points. By having min_samples have a reasonably large value, we will be able to detect outliers since they won't be close enough to enough points to be considered a cluster.\n",
    "\n",
    "5) \n",
    "    For reccommendation systems where we try to predict ratings by users for movies for example, we can have a plot for every movie, where we have ratings as data points for each user. We can then use a technique such as DBSCAN to cluster the points based on a reasonable eps and min_samples value. Since the goal is ultimately to predict ratings for unseen users, we can try to find the largest cluster and take the average of those scores within to be a logical predictor for the rating of a movie for unseen users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea9c37-34c9-4b3e-a2df-e00cedd3e8ae",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab723dc5-4ea6-4c44-ace9-bf345bf8c120",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
